{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic Dataset Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from DecisionTree import DecisionTree\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>684 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Survived\n",
       "0              1       3    0  22.0      1      0   7.2500       0.0         0\n",
       "1              2       1    1  38.0      1      0  71.2833       1.0         1\n",
       "2              3       3    1  26.0      0      0   7.9250       0.0         1\n",
       "3              4       1    1  35.0      1      0  53.1000       0.0         1\n",
       "4              5       3    0  35.0      0      0   8.0500       0.0         0\n",
       "..           ...     ...  ...   ...    ...    ...      ...       ...       ...\n",
       "883          884       2    0  28.0      0      0  10.5000       0.0         0\n",
       "884          885       3    0  25.0      0      0   7.0500       0.0         0\n",
       "886          887       2    0  27.0      0      0  13.0000       0.0         0\n",
       "887          888       1    1  19.0      0      0  30.0000       0.0         1\n",
       "889          890       1    0  26.0      0      0  30.0000       1.0         1\n",
       "\n",
       "[684 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/trainTitanic.csv\")\n",
    "filter_df = df.drop('Name', axis=1)\n",
    "filter_df = filter_df.drop('Ticket', axis=1)\n",
    "filter_df = filter_df.drop('Cabin', axis=1)\n",
    "\n",
    "test_df = filter_df\n",
    "test_df = test_df[test_df[\"Age\"].notna()]\n",
    "\n",
    "cols = test_df.columns.tolist()\n",
    "cols = cols[0:1] + cols[2:] + cols[1:2]\n",
    "\n",
    "test_df = test_df[cols]\n",
    "\n",
    "sex_mapping = {'male': 0, 'female': 1}\n",
    "embarked_mapping = {'S': 0, 'C': 1}\n",
    "\n",
    "test_df['Sex'] = test_df['Sex'].map(sex_mapping)\n",
    "test_df['Embarked'] = test_df['Embarked'].map(embarked_mapping)\n",
    "\n",
    "test_df = test_df.dropna()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 22.0, ..., 7.25, 0.0, 0],\n",
       "       [1, 1, 38.0, ..., 71.2833, 1.0, 1],\n",
       "       [3, 1, 26.0, ..., 7.925, 0.0, 1],\n",
       "       ...,\n",
       "       [2, 0, 27.0, ..., 13.0, 0.0, 0],\n",
       "       [1, 1, 19.0, ..., 30.0, 0.0, 1],\n",
       "       [1, 0, 26.0, ..., 30.0, 1.0, 1]], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np = test_df.to_numpy(dtype=object)[:, 1:]\n",
    "data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Random Forest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RandomForest import RandomForest\n",
    "\n",
    "params = dict(max_depth=20, min_samples_split=10, bagging=True)\n",
    "\n",
    "forest1 = RandomForest.RandomForest(n_features=5, n_estimators=100, tree_params=params, bagging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1.build_forest(data=data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 22.0, 1, 0, 7.25, 0.0, 0],\n",
       "       [1, 1, 38.0, 1, 0, 71.2833, 1.0, 1],\n",
       "       [3, 1, 26.0, 0, 0, 7.925, 0.0, 1],\n",
       "       [1, 1, 35.0, 1, 0, 53.1, 0.0, 1],\n",
       "       [3, 0, 35.0, 0, 0, 8.05, 0.0, 0],\n",
       "       [1, 0, 54.0, 0, 0, 51.8625, 0.0, 0],\n",
       "       [3, 0, 2.0, 3, 1, 21.075, 0.0, 0],\n",
       "       [3, 1, 27.0, 0, 2, 11.1333, 0.0, 1],\n",
       "       [2, 1, 14.0, 1, 0, 30.0708, 1.0, 1],\n",
       "       [3, 1, 4.0, 1, 1, 16.7, 0.0, 1]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = data_np[:10, :]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = forest1.calculate_accuracy(data=subset)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9312865497076024"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now calculate accuracy over whole training set\n",
    "all_train_acc = forest1.calculate_accuracy(data=data_np)\n",
    "all_train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = data_np[:,7:8]\n",
    "mapper = np.vectorize(lambda x: \"No\" if x == 0 else \"Yes\")\n",
    "y_pred_mapped = mapper(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/neuralNets/lib/python3.12/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "forest_sklearn = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=10, max_features=\"sqrt\", bootstrap=True)\n",
    "forest_sklearn = forest_sklearn.fit(data_np[:,:7], y_pred_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes'], dtype='<U3')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all = forest_sklearn.predict(data_np[:,:7])\n",
    "predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8991228070175439"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_mapped, predictions_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, sklearn got 90% accuracy on the training set, while my implementation got 92%. I doubt that my implementation is better than skelearn's (it's definitely slower that's for sure). Anyway, this seems to be working, so I think I'll move on to tyring to pre-process the dataset and gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_np)\n",
    "data_np_train = data_np[:480,:]\n",
    "data_np_test = data_np[480:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8186274509803921"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My Implementation\n",
    "params = dict(max_depth=20, min_samples_split=10, bagging=True)\n",
    "forest1 = RandomForest.RandomForest(n_features=5, n_estimators=100, tree_params=params, bagging=True)\n",
    "forest1.build_forest(data=data_np_train)\n",
    "all_train_acc = forest1.calculate_accuracy(data=data_np_test)\n",
    "all_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/neuralNets/lib/python3.12/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8431372549019608"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn Implementation\n",
    "y_pred_train = data_np_train[:,7:8]\n",
    "mapper = np.vectorize(lambda x: \"No\" if x == 0 else \"Yes\")\n",
    "y_pred_mapped_train = mapper(y_pred_train)\n",
    "\n",
    "forest_sklearn = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=10, max_features=\"sqrt\", bootstrap=True)\n",
    "forest_sklearn = forest_sklearn.fit(data_np_train[:,:7], y_pred_mapped_train)\n",
    "\n",
    "y_pred_test = data_np_test[:,7:8]\n",
    "y_pred_mapped_test = mapper(y_pred_test)\n",
    "predictions_all = forest_sklearn.predict(data_np_test[:,:7])\n",
    "accuracy_score(y_pred_mapped_test, predictions_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, not too bad actually. I think my model is overfitting a bit more (that's why there's lower accuracy on the test set). Now, I can move on to pre-processing the tennis data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralNets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
